\section{Summary of key findings}
We introduced the PM method by focusing on its key aspects: mass assignment, Poisson's equation solver, gradient approximation for field calculation, and field interpolation.
This systematic description led us to observe the connection between the Fourier transform and the diagonalization of the Laplace operator.
This connection, in turn, clarified the derivation of the Green's function for the so-called ``Poor Man's'' Poisson solver.

The error analysis of the PM method of the field due to a single mass showed that the best results were obtained using the TSC scheme for mass assignment and field interpolation, which confirmed our expectations.
The global error analysis, on the other hand, yielded results that at first seemed at odds with the preceding theoretical developments -- the NGP scheme seemed to have performed best by giving results closest to the PP method.
This conclusion was refuted based on an observation that the forces generated by the PM method are ``inherently softened.''
Indeed, a comparison with softened PP forces spoke in favor of the higher-order schemes (CIC and TSC).

We found that our GPU implementation is up to 12 times faster compared to the multithreaded CPU implementation but only if data transfers between the CPU and GPU and disk I/O are limited; when these conditions are not met, the speedup is more modest -- only five-fold.
We also investigated if additional performance gains are possible if the data needed for the gradient calculation is first fetched into shared memory, but no such gain was observed.

Turning to the \PThreeM{} method, our focus was twofold: describing an optimal Green's function that closely matches a given reference force and optimizing the short-range correction.

The error analysis conducted in the first area showed that in our implementation of the \PThreeM{} method, the mesh force correctly reproduced the reference force for the optimal Green's function.
Interestingly, our analysis showed that using the $S_1$ shape yields smaller errors (difference between mesh and reference force) compared to the $S_2$ shape.
We could not find any similar study in the literature, however, that would confirm if our observation is valid.
Our single-source analysis confirmed that the TSC scheme minimizes the force approximation error, as expected.

We proposed a simple lock-free parallelization scheme of the short-range correction procedure, which yielded a four-fold speedup.
We consider this result satisfactory, although further optimization of the current implementation of the \PThreeM{} method is highly desirable.
Confusingly, the optimization proposed in \cite{Hockney1988} (sorting the HOC lists) did not improve performance; in fact, it had the opposite effect.
We confirmed that sorting the HOC lists leads, in a lot of cases, to early returns from the short-range correction loop, however, this does not offset the added cost of sorting the lists.
Finally, the global error analysis confirmed that higher-order schemes lead to smaller approximation errors and that the error decreases with increasing cutoff radius and particle diameter, as we expected.
We found that the global error can be reduced beyond 1\% if $a \geq 4 H$.

Finally, we examined the Barnes-Hut algorithm, paying particular attention to its accuracy in force approximation and computational efficiency.
Our study of the Barnes-Hut algorithm showed that the approximation error is minimized for small values of the opening angle $\theta$ and that the running time of the algorithm decreases with increasing values of $\theta$ -- both results were to be expected.
Additionally, we confirmed that including the quadrupole moment in the force calculation leads to a significant reduction in the error of force approximation.
We also found that the added cost due to including the quadrupole moment is negligible and that the error can be brought down to as little as $10^{-5}$.
Interestingly, $\theta = 0$ did not cause the error to vanish completely, likely due to numerical errors.

We attempted to improve the performance of the Barnes-Hut algorithm by accelerating the tree construction step.
For that, we used the approach based on Z-ordering the particles and inserting them at the last-visited node in the tree with the hope that this will lead to better cache utilization.
The approach was successful and allowed us to achieve around 140\% speedup over the standard tree-construction algorithm which translated into 115\% speedup of the whole simulation.

The implemented methods were tested in three scenarios: a simulation of a spiral galaxy, a globular cluster, and a collision of two galaxies.

The first scenario did not demonstrate the superiority of any particular method.
All methods yielded similar evolution of the spiral galaxy, and the plots of energy, momentum, and angular momentum were practically the same for all methods.

Similarly, the globular cluster simulation gave similar results for all tested methods.

In the galaxy collision simulation scenario, the \PThreeM{} method yielded the most physically realistic results, conserving both angular momentum and momentum.
The energy, however, oscillated violently around the expected values and so was only \textit{on average} constant.

In conclusion, the \PThreeM{} and Barnes-Hut codes yielded the best results, with the Barnes-Hut algorithm outperforming \PThreeM{} in the tested scenarios.
At the same time, the Barnes-Hut algorithm suffers from issues with momentum conservation, which could likely be mitigated by incorporating higher-order multipole terms.
Overall, this work demonstrates the feasibility and trade-offs of classical $N$-body methods for different astrophysical simulations, laying the groundwork for future improvements in both accuracy and computational performance.
