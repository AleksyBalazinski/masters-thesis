\section{Summary of key findings}
We introduced the PM method by focusing on its key aspects: mass assignment, Poisson's equation solver, gradient approximation for field calculation, and interpolation.
This systematic description led us to observe the connection between the Fourier transform and the diagonalization of the Laplacian operator.
This connection, in turn, clarified the derivation of the Green's function for the so-called ``Poor Man's'' Poisson solver.

The error analysis of the PM method of the field due to a single mass showed that the best results were obtained using the TSC scheme for mass assignment and field interpolation, which confirmed our expectations.
The global error analysis, on the other hand, yielded results which at first seemed at odds with the preceding theoretical developments -- the NGP scheme seemed to have performed best by giving results closest to the PP method.
This conclusion was refuted based on an observation that the forces generated by the PM method are ``inherently softened''.
Indeed, a comparison with softened PP forces spoke in favor of the higher-order schemes (CIC and TSC).

We found that our GPU implementation is up to 12 times faster compared to the multithreaded CPU implementation but only if data transfers between the CPU and GPU and disk I/O are limited; when these conditions are not met, the speedup is more modest -- only five-fold.
We also investigated if additional performance gains are possible if the data needed for the gradient calculation is first fetched into shared memory but no such gain was observed.

Turning to the \PThreeM{} method, our focus was twofold: designing an optimal Green's function that closely matches a given reference force and the short-range correction.

The error analysis conducted in the first area showed that in our implementation of the PM method, the mesh force correctly reproduced the reference force once the appropriate Green's function was used.
Interestingly, our analysis showed that using the $S_1$ shape gives smaller errors (difference between mesh- and reference force) compared to the $S_2$ shape.
We could not find any similar study in the literature, however, that could confirm if our observation is valid.
Our single-source analysis confirmed that the TSC scheme minimizes the force approximation error, as expected.

We proposed a simple lock-free parallelization scheme of the short-range correction procedure which yielded a four-fold speedup.
We consider this result satisfactory although further optimization of the current implementation of the \PThreeM{} method is highly desirable.
Confusingly, the optimization proposed in \cite{Hockney1988} (sorting HOC lists) did not improve the performance and produced the opposite effect.
We confirmed that sorting the HOC lists leads in a lot of cases to early returns from the short-range correction loop, however, this does not seem to offset the added cost of sorting the lists.
Finally, the global error analysis confirmed that higher-order schemes lead to smaller approximation errors and that the error decreases with increasing cutoff radius and particle diameter, as we expected.
We found that the global error can be reduced beyond 1\% if $a \geq 4 H$.

Finally, we examined the Barnes-Hut algorithm, with particular attention to its force approximation accuracy and computational efficiency.
Our study of the Barnes-Hut algorithm showed that the approximation error is minimized for small values of the opening angle $\theta$ and that the running time of the algorithm decreases with increasing values of $\theta$ -- both results were to be expected.
Additionally, we confirmed that including the quadrupole moment in the force calculation leads to a significant reduction in the error of force approximation.
We also found that the added cost due to including the quadrupole moment is negligible and that the error can be brought down to as little as $10^{-5}$.
Interestingly, $\theta = 0$ did not cause the error to vanish completely, likely due to numerical errors.

We attempted to improve the performance of the Barnes-Hut algorithm by accelerating the tree construction step.
For that, we used the approach based on Z-ordering the particles and inserting them at the last-visited node in the tree with the hope that this will lead to better cache utilization.
The approach turned out to be successful and allowed us to achieve around 40\% speedup over the standard tree-construction algorithm which translated into 13\% speedup of the whole simulation.

The implemented methods were tested in three scenarios: a simulation of a spiral galaxy, a globular cluster, and a collision of two galaxies.

The first scenario did not demonstrate the superiority of any particular method.
All methods yielded similar evolution of the spiral galaxy and the plots of energy, momentum, and angular momentum were practically the same for all methods.

Similarly, the globular cluster simulation gave similar results for all tested methods.

In the galaxy collision simulation scenario, the \PThreeM{} method yielded the most physical results, conserving angular momentum and momentum.
The energy, however, oscillated violently around the expected values, and so was only \textit{on average} constant.

In conclusion, the \PThreeM{} and Barnes-Hut codes provided the best results, with the Barnes-Hut algorithm being faster than \PThreeM{} in the tested scenarios.
At the same time, the Barnes-Hut algorithm has problems with momentum conservation but these problems could probably be mitigated by including higher multipole terms.
Overall, this work demonstrates the feasibility and trade-offs of classical $N$-body methods for different astrophysical simulations, laying the groundwork for future improvements in both accuracy and computational performance.
